{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "867c4a04-4d57-4f9d-a11b-e9d9cdd3bf6d",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     C:\\Users\\Ir\\AppData\\Roaming\\nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import pandas as pd\n",
    "\n",
    "df=pd.read_csv('Emotion_classify_Data.csv')\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stop_words = set(stopwords.words('english'))\n",
    "\n",
    "def preprocess_text(text):\n",
    "    # Lowercase the text\n",
    "    text = text.lower()\n",
    "    # Remove special characters, numbers, and punctuation\n",
    "    text = re.sub(r'[^a-z\\s]', '', text)\n",
    "    # Tokenize and remove stopwords\n",
    "    tokens = text.split()\n",
    "    tokens = [word for word in tokens if word not in stop_words]\n",
    "\n",
    "    return ' '.join(tokens)\n",
    "\n",
    "df['cleaned_text'] = df['Comment'].apply(preprocess_text)\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "e5b3ef43-b99a-436c-8678-32a229af1041",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Ir\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\transformers\\tokenization_utils_base.py:1601: FutureWarning: `clean_up_tokenization_spaces` was not set. It will be set to `True` by default. This behavior will be depracted in transformers v4.45, and will be then set to `False` by default. For more details check this issue: https://github.com/huggingface/transformers/issues/31884\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.model_selection import train_test_split\n",
    "model = SentenceTransformer('all-MiniLM-L6-v2')\n",
    "\n",
    "X = model.encode(df['cleaned_text'])\n",
    "y=df['Emotion']\n",
    "\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "c05e9c39-f271-4e2e-bb82-d0f0f51ef987",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "       anger       0.83      0.79      0.81       392\n",
      "        fear       0.80      0.85      0.82       416\n",
      "         joy       0.85      0.83      0.84       380\n",
      "\n",
      "    accuracy                           0.82      1188\n",
      "   macro avg       0.83      0.82      0.82      1188\n",
      "weighted avg       0.82      0.82      0.82      1188\n",
      "\n"
     ]
    }
   ],
   "source": [
    "from sklearn.neural_network import MLPClassifier\n",
    "model_MLP = MLPClassifier(hidden_layer_sizes=(128, 64), activation='relu', max_iter=200)\n",
    "model_MLP.fit(X_train, y_train)\n",
    "\n",
    "# Evaluate the model\n",
    "from sklearn.metrics import classification_report\n",
    "y_pred = model_MLP.predict(X_test)\n",
    "print(classification_report(y_test, y_pred))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "39c1d328-ee4d-474e-87e2-847378b905dc",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "WARNING:tensorflow:From C:\\Users\\Ir\\AppData\\Local\\Programs\\Python\\Python312\\Lib\\site-packages\\tf_keras\\src\\losses.py:2976: The name tf.losses.sparse_softmax_cross_entropy is deprecated. Please use tf.compat.v1.losses.sparse_softmax_cross_entropy instead.\n",
      "\n"
     ]
    }
   ],
   "source": [
    "import tkinter as tk\n",
    "from tkinter import scrolledtext\n",
    "from sentence_transformers import SentenceTransformer\n",
    "from sklearn.neural_network import MLPClassifier\n",
    "import numpy as np\n",
    "\n",
    "# Sample setup (replace these with your real model and data)\n",
    "# Assuming your model and classifier are already trained\n",
    "\n",
    " # Dummy training\n",
    "\n",
    "# Function to process user input and get model predictions\n",
    "def get_prediction(user_input):\n",
    "    try:\n",
    "        # Generate embeddings for user input\n",
    "        embedding = model.encode([user_input])\n",
    "        # Predict emotion\n",
    "        prediction = model_MLP.predict(embedding)\n",
    "        return f\"Predicted Emotion: {prediction[0]}\"\n",
    "    except Exception as e:\n",
    "        return f\"Error: {str(e)}\"\n",
    "\n",
    "# GUI Setup\n",
    "def send_message():\n",
    "    user_message = user_input_box.get(\"1.0\", tk.END).strip()\n",
    "    if user_message:\n",
    "        # Display the user message\n",
    "        chat_area.config(state=tk.NORMAL)\n",
    "        chat_area.insert(tk.END, f\"You: {user_message}\\n\")\n",
    "\n",
    "        # Get the model's response\n",
    "        bot_response = get_prediction(user_message)\n",
    "        chat_area.insert(tk.END, f\"AI: {bot_response}\\n\")\n",
    "        chat_area.config(state=tk.DISABLED)\n",
    "\n",
    "        # Clear the input box\n",
    "        user_input_box.delete(\"1.0\", tk.END)\n",
    "    else:\n",
    "        # If input is empty\n",
    "        chat_area.config(state=tk.NORMAL)\n",
    "        chat_area.insert(tk.END, \"AI: Please type a message!\\n\")\n",
    "        chat_area.config(state=tk.DISABLED)\n",
    "\n",
    "# Main tkinter window\n",
    "root = tk.Tk()\n",
    "root.title(\"AI Chat Interface\")\n",
    "\n",
    "# Chat history area\n",
    "chat_area = scrolledtext.ScrolledText(root, wrap=tk.WORD, state=tk.DISABLED, height=20, width=50)\n",
    "chat_area.grid(row=0, column=0, columnspan=2, padx=10, pady=10)\n",
    "\n",
    "# User input area\n",
    "user_input_box = tk.Text(root, height=3, width=40)\n",
    "user_input_box.grid(row=1, column=0, padx=10, pady=5)\n",
    "\n",
    "# Send button\n",
    "send_button = tk.Button(root, text=\"Send\", command=send_message, bg=\"green\", fg=\"white\")\n",
    "send_button.grid(row=1, column=1, padx=10, pady=5)\n",
    "\n",
    "# Run the tkinter event loop\n",
    "root.mainloop()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "137686b3-4d55-42d0-88b4-af5c9e91c8c8",
   "metadata": {},
   "outputs": [],
   "source": [
    "unseen_data = [\n",
    "    \"I am so excited about the trip tomorrow!\",\n",
    "    \"Why does everything have to go wrong for me?\",\n",
    "    \"I'm feeling really happy and grateful today.\",\n",
    "    \"This is the most frustrating experience I've ever had.\",\n",
    "    \"I can't believe how amazing this day has been!\",\n",
    "    \"I feel lonely and left out sometimes.\",\n",
    "    \"Nothing seems to work, and it's making me angry.\",\n",
    "    \"I'm just so content and at peace right now.\"\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "ccb4038a-6727-4c9c-98be-acbdcbef32db",
   "metadata": {},
   "outputs": [],
   "source": [
    "input = model.encode(unseen_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "551d994d-dc9a-4d05-b4b0-cfaa01f6dd3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "['joy' 'fear' 'joy' 'anger' 'joy' 'fear' 'anger' 'joy']\n"
     ]
    }
   ],
   "source": [
    "predictions = model_MLP.predict(input)\n",
    "print(predictions)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "3830fb18-0e87-4dbd-a482-b7974d7c49fe",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Note: you may need to restart the kernel to use updated packages.\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "ERROR: Could not find a version that satisfies the requirement xelatex (from versions: none)\n",
      "\n",
      "[notice] A new release of pip is available: 24.2 -> 24.3.1\n",
      "[notice] To update, run: python.exe -m pip install --upgrade pip\n",
      "ERROR: No matching distribution found for xelatex\n"
     ]
    }
   ],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "933756e3-de39-4033-a12e-f6657a0fe2a3",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
